{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Doppelganger!\n",
    "Welcome to the Doppelganger example. If you have not already done so, please see the [README document](https://github.com/sidewalklabs/doppelganger/blob/master/README.md) for installation instructions and information on what Doppelganger is doing under the hood. For a simplified walkthrough, take a look at [doppelganger_example_simple](./doppelganger_example_simple.ipynb)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## What's in this Example?\n",
    "This workbook acts on a single PUMA and carries out the following tasks: \n",
    "1. Builds household- and person-specific Bayesian Networks for an individual PUMA; \n",
    "2. Allocates PUMS households to an individual PUMA consistent with subjectively-weighted marginal controls; and,\n",
    "3. Replaces the drawn PUMS population with synthetic people created by moving through and person-specific Bayesian Network."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Housekeeping\n",
    "Before we get going, let's take care of some housekeeping tasks to make your Doppelganger Example experience as seamless as possible. \n",
    "\n",
    "We have included a cross-walk between PUMAs and Census tracts that we'll use later. Please navigate to this file and unzip it in the same directory. The file is here:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ./examples/sample_data/2010_puma_tract_mapping.txt.zip"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The example operates on a single PUMA in California (`00106`). In Step 01 below, you'll see that we have already extracted PUMS data for this PUMA, so we'd recommend that you do not change to your favorite PUMA just yet (here's a set of [reference maps for California](https://www.census.gov/geo/maps-data/maps/2010puma/st06_ca.html) -- all states are available). But once you get comfortable with the tools, download the PUMS data for the PUMA of your choice, and go for it. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "STATE = '06'\n",
    "PUMA = '00106'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Later in the example we grab some Census data using the [Census API](https://www.census.gov/developers/). Enter your Census key below (if you need one, you can get one for free [here](http://api.census.gov/data/key_signup.html)). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "MY_CENSUS_KEY = 'd95e144b39e17f929287714b0b8ba9768cecdc9f'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This example will generate a variety of output. Please specify where you'd like this data written to disk."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_dir = '../../../Data/20190217_doppelgangerOutputs'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Configuration\n",
    "We'll need to configure your computing environment and load in the configuration file before getting started. \n",
    "### Import the relevant Doppelganger Python packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "import os\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "from doppelganger import (\n",
    "    allocation,\n",
    "    inputs,\n",
    "    Configuration,\n",
    "    HouseholdAllocator,\n",
    "    PumsData,\n",
    "    SegmentedData,\n",
    "    BayesianNetworkModel,\n",
    "    Population,\n",
    "    Preprocessor,\n",
    "    Marginals\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load the Doppelganger example configuration file\n",
    "This file does the following three things:\n",
    "1. Defines person-specific variables in `person_fields`. In the example, you'll see `age`, `sex`, and `individual_income`. These variables are mapped to the PUMS variables in `inputs.py`. For example, `age` in Doppelganger is mapped to the PUMS variable `agep`. To use other variables from the PUMS with Doppelganger, you'll need to map their relationships in `inputs.py` and specify them here. \n",
    "2. Defines household-specific variables in `household_fields`. In the example, you'll see `household_income` and `num_vehicles`. As with the person-specific variables, you'll need to modify `inputs.py` to use other variables in Doppelganger.\n",
    "3. Defines procedures to process input variables into bins in `preprocessing`.\n",
    "4. Defines the structure of the household and person Bayesian Networks in `network_config_files`.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "configuration = Configuration.from_file('sample_data/config.json')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With the `configuration` in hand, we can create a `preprocessor` object that will create methods to apply to the household and person PUMS data. In the current configuration, the `preprocessor` bins the individual income variable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "preprocessor = Preprocessor.from_config(configuration.preprocessing_config)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 01: Let's Build some Bayesian Networks!\n",
    "Bayesian Networks are built using the specification (`network_config_files`) in the configuration file and cleaned PUMS data. Up first: let's read in and clean the PUMS data.\n",
    "\n",
    "### Data reads\n",
    "#### Household Data\n",
    "The fields we need from the household data is the union of those defined in the `allocation.DEFAULT_HOUSEHOLD_FIELDS` and those defined `household_categories` section of the configuration file. The raw/dirty data collected for our example PUMA is available [here](https://www.census.gov/programs-surveys/acs/data/pums.html)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "household_fields = tuple(set(\n",
    "    field.name for field in allocation.DEFAULT_HOUSEHOLD_FIELDS).union(\n",
    "        set(configuration.household_fields)\n",
    "))\n",
    "\n",
    "households_data = PumsData.from_csv('sample_data/households_00106_dirty.csv').clean(\n",
    "    household_fields, preprocessor, puma=PUMA\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'doppelganger.datasource.CleanedData'>\n",
      "<class 'tuple'>\n",
      "('state', 'household_income', 'puma', 'num_vehicles', 'num_people', 'household_weight', 'serial_number')\n"
     ]
    }
   ],
   "source": [
    "##Dare testing\n",
    "print(type(households_data))\n",
    "print(type(household_fields))\n",
    "print(household_fields)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Person Data\n",
    "The `allocation.DEFAULT_PERSON_FIELDS` defines a set of fields that can be used to create the `persons_data`; we take the union of these defaults with those defined in the `person_categories` section of the configuration file. This data is then extracted from the raw/dirty PUMS data. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "persons_fields = tuple(set(\n",
    "    field.name for field in allocation.DEFAULT_PERSON_FIELDS).union(\n",
    "        set(configuration.person_fields)\n",
    "))\n",
    "persons_data = PumsData.from_csv('sample_data/persons_00106_dirty.csv').clean(\n",
    "    persons_fields, preprocessor, puma=PUMA\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Bayesian Networks\n",
    "The example below shows the training of a person-level model. It requires the following inputs:\n",
    "1. The `persons_data`, which was created in the previous step;\n",
    "2. A list of variables you want to consider in the training -- taken here from our configuration file; and,\n",
    "3. An optional weight if you want to weight the records (in the example, we use the PUMS variable `pwgtp`, which is defined in `inputs.py`. \n",
    "\n",
    "Once the training data is prepared, the training needs the `person_structure`, which is defined as in the `network_config_files` section of the configuration file, and the `person_fields`, which are also defined in the configuration file. The example `person_structure` specifies a network with three nodes (`age`, `sex`, and `income`) and two edges (`age` --> `income`, and `sex` --> `income`). The example `household_structure` specifies a network with three nodes (`num_people`, `household_income`, and `num_vehicles`) and three edges (`num_people` --> `household_income`, `num_people` --> `num_vehicles`, and `household_income` --> `num_vehicles`).\n",
    "\n",
    "<img src=\"./images/structure.png\" alt=\"Structure Image\" style=\"width: 500px;\"/>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "person_training_data = SegmentedData.from_data(\n",
    "    persons_data,\n",
    "    list(configuration.person_fields),\n",
    "    weight_field = inputs.PERSON_WEIGHT.name\n",
    ")\n",
    "person_model = BayesianNetworkModel.train(\n",
    "    person_training_data,\n",
    "    configuration.person_structure,\n",
    "    configuration.person_fields\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'doppelganger.bayesnets.BayesianNetworkModel'>\n",
      "<doppelganger.bayesnets.BayesianNetworkModel object at 0x10da97eb8>\n",
      "<class 'doppelganger.bayesnets.SegmentedData'>\n"
     ]
    }
   ],
   "source": [
    "print(type(person_model))\n",
    "print(person_model)\n",
    "print(type(person_training_data))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The Bayesian Networks can also be fully segmented. In the below example, we rebuild the networks, fully segmented by age category via the `segmenter` functionality. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "person_segmentation = lambda x: x[inputs.AGE.name]\n",
    "\n",
    "person_training_data = SegmentedData.from_data(\n",
    "    persons_data,\n",
    "    list(configuration.person_fields),\n",
    "    inputs.PERSON_WEIGHT.name,\n",
    "    person_segmentation\n",
    ")\n",
    "person_model = BayesianNetworkModel.train(\n",
    "    person_training_data,\n",
    "    configuration.person_structure,\n",
    "    configuration.person_fields\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The Bayesian Network can be written to disk and read from disk as follows."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "person_model_filename = os.path.join(output_dir, 'person_model.json')\n",
    "person_model.write(person_model_filename)\n",
    "person_model_reloaded = BayesianNetworkModel.from_file(person_model_filename)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Following the same steps as above, you can also build a household network."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "household_segmenter = lambda x: x[inputs.NUM_PEOPLE.name]\n",
    "\n",
    "household_training_data = SegmentedData.from_data(\n",
    "    households_data,\n",
    "    list(configuration.household_fields),\n",
    "    inputs.HOUSEHOLD_WEIGHT.name,\n",
    "    household_segmenter,\n",
    ")\n",
    "household_model = BayesianNetworkModel.train(\n",
    "    household_training_data,\n",
    "    configuration.household_structure,\n",
    "    configuration.household_fields\n",
    ")\n",
    "\n",
    "household_model_filename = os.path.join(output_dir, 'household_model.json')\n",
    "household_model.write(household_model_filename)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 02: Allocate PUMS households to the PUMA\n",
    "The sample data comes with a set of marginals that can be used in the allocation step. This file is named `sample_data/marginals_00106.csv`. To demonstrate how marginals can be created, we create them here. Note that this step will take a few minutes. If you want to skip it, use the `controls = Marginals.from_csv('sample_data/marginals_00106.csv')` call in the subsequent code box. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Skip puma 00106 tract 430101\n",
      "Skip puma 00106 tract 430102\n",
      "Skip puma 00106 tract 430200\n",
      "Skip puma 00106 tract 430300\n",
      "Skip puma 00106 tract 430400\n",
      "Skip puma 00106 tract 430500\n",
      "Skip puma 00106 tract 430600\n",
      "Skip puma 00106 tract 430700\n",
      "Skip puma 00106 tract 430800\n",
      "Skip puma 00106 tract 430900\n",
      "Skip puma 00106 tract 431000\n",
      "Skip puma 00106 tract 431100\n",
      "Skip puma 00106 tract 431200\n",
      "Skip puma 00106 tract 433700\n",
      "Skip puma 00106 tract 433800\n",
      "Skip puma 00106 tract 433900\n",
      "Skip puma 00106 tract 434000\n",
      "Skip puma 00106 tract 435200\n",
      "Skip puma 00106 tract 435300\n",
      "Skip puma 00106 tract 435500\n",
      "Skip puma 00106 tract 435601\n",
      "Skip puma 00106 tract 435602\n",
      "Skip puma 00106 tract 435700\n",
      "Skip puma 00106 tract 435800\n",
      "Skip puma 00106 tract 435900\n",
      "Skip puma 00106 tract 436000\n",
      "Skip puma 00106 tract 436100\n",
      "Skip puma 00106 tract 436200\n",
      "Skip puma 00106 tract 436402\n"
     ]
    }
   ],
   "source": [
    "if MY_CENSUS_KEY:\n",
    "    new_marginal_filename = os.path.join(output_dir, 'new_marginals.csv')\n",
    "\n",
    "    with open('sample_data/2010_puma_tract_mapping.txt') as csv_file:\n",
    "        csv_reader = csv.DictReader(csv_file)\n",
    "        marginals = Marginals.from_census_data(\n",
    "            csv_reader, MY_CENSUS_KEY, state=STATE, pumas=[PUMA]\n",
    "        )\n",
    "        marginals.write(new_marginal_filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "controls = Marginals.from_csv(new_marginal_filename) # use this one to use your new marginals\n",
    "#controls = Marginals.from_csv('sample_data/marginals_00106.csv') # use this one if you want to skip previous step"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'doppelganger.allocation.HouseholdAllocator'>\n"
     ]
    }
   ],
   "source": [
    "#Dare testing\n",
    "print(allocation.HouseholdAllocator)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With the above marginal controls, the methods in `allocation.py` allocate discrete PUMS households to the subject PUMA. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Length mismatch: Expected axis has 0 elements, new values have 4 elements",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-26-3b73fa6e09f0>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mallocator\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mHouseholdAllocator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfrom_cleaned_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcontrols\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhouseholds_data\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpersons_data\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/doppelganger/allocation.py\u001b[0m in \u001b[0;36mfrom_cleaned_data\u001b[0;34m(marginals, households_data, persons_data)\u001b[0m\n\u001b[1;32m     75\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     76\u001b[0m         households, persons = HouseholdAllocator._format_data(\n\u001b[0;32m---> 77\u001b[0;31m             households_data.data, persons_data.data)\n\u001b[0m\u001b[1;32m     78\u001b[0m         \u001b[0mallocated_households\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mallocated_persons\u001b[0m \u001b[0;34m=\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     79\u001b[0m             \u001b[0mHouseholdAllocator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_allocate_households\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhouseholds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpersons\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmarginals\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/doppelganger/allocation.py\u001b[0m in \u001b[0;36m_format_data\u001b[0;34m(households_data, persons_data)\u001b[0m\n\u001b[1;32m    210\u001b[0m         \u001b[0mhp_ages\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpandas\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_dummies\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpersons_data\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mAGE\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    211\u001b[0m         \u001b[0mhp_ages\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolumns\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mHouseholdAllocator\u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 212\u001b[0;31m             \u001b[0;34m.\u001b[0m\u001b[0m_str_broadcast\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mAGE\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mAGE\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpossible_values\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    213\u001b[0m         \u001b[0mpersons_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpandas\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconcat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mpersons_data\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhp_ages\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    214\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/pandas/core/generic.py\u001b[0m in \u001b[0;36m__setattr__\u001b[0;34m(self, name, value)\u001b[0m\n\u001b[1;32m   4387\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4388\u001b[0m             \u001b[0mobject\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__getattribute__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 4389\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mobject\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__setattr__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   4390\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mAttributeError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4391\u001b[0m             \u001b[0;32mpass\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/properties.pyx\u001b[0m in \u001b[0;36mpandas._libs.properties.AxisProperty.__set__\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/pandas/core/generic.py\u001b[0m in \u001b[0;36m_set_axis\u001b[0;34m(self, axis, labels)\u001b[0m\n\u001b[1;32m    644\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    645\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_set_axis\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 646\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_data\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_axis\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    647\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_clear_item_cache\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    648\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/pandas/core/internals.py\u001b[0m in \u001b[0;36mset_axis\u001b[0;34m(self, axis, new_labels)\u001b[0m\n\u001b[1;32m   3321\u001b[0m             raise ValueError(\n\u001b[1;32m   3322\u001b[0m                 \u001b[0;34m'Length mismatch: Expected axis has {old} elements, new '\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3323\u001b[0;31m                 'values have {new} elements'.format(old=old_len, new=new_len))\n\u001b[0m\u001b[1;32m   3324\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3325\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maxes\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnew_labels\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: Length mismatch: Expected axis has 0 elements, new values have 4 elements"
     ]
    }
   ],
   "source": [
    "allocator = HouseholdAllocator.from_cleaned_data(controls, households_data, persons_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 03: Replace the PUMS Persons with Synthetic Persons created from the Bayesian Network\n",
    "It may be convenient to replace the source population with a synthetic population -- to add heterogeniety to the synthetic population or to obscure the source data set. In the below example we generate a set of persons and households using the `allocator` (the PUMS persons allocated to tracts), the Bayesian Networks (`person_model`, `household_model`)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "population = Population.generate(\n",
    "    allocator, person_model, household_model\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can access the people and households as Pandas DataFrames and work with them directly. Households and people are unique by `(tract, serial_number, repeat_index)`. `serial_number` is the PUMS serialno for the household."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "people = population.generated_people\n",
    "households = population.generated_households\n",
    "\n",
    "sort_cols = [inputs.HOUSEHOLD_ID.name]\n",
    "\n",
    "print(people.sort_values(sort_cols).head())\n",
    "print(households.sort_values(sort_cols).head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To create one fat table of people and household attributes we can join on inputs.HOUSEHOLD_ID.name:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "combined = pd.merge(people, households, on=[inputs.HOUSEHOLD_ID.name])\n",
    "\n",
    "print(combined.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Or write them to disk:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "generated_people_filename = os.path.join(output_dir, 'generated_people.csv')\n",
    "generated_households_filename = os.path.join(output_dir, 'generated_households.csv')\n",
    "\n",
    "population.write(generated_people_filename, generated_households_filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
